{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Frame extraction from video\n",
    "- Once downloaded the first episode is read in and every 5th frame is saved to disc.\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import ViTFeatureExtractor, ViTModel\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import timm\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set plot parameters\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "plt.rcParams['axes.grid'] = False\n",
    "plt.style.use('dark_background')\n",
    "plt.rcParams[\"axes.spines.top\"] = False\n",
    "plt.rcParams[\"axes.spines.right\"] = False\n",
    "plt.rcParams[\"font.size\"] = 13\n",
    "\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>file_path</th>\n",
       "      <th>file_name</th>\n",
       "      <th>creation</th>\n",
       "      <th>duration</th>\n",
       "      <th>resolution</th>\n",
       "      <th>fps</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>./data/videos/individual-rotifer/2024_0201_152...</td>\n",
       "      <td>2024_0201_152310_089.MP4</td>\n",
       "      <td>1.706962e+09</td>\n",
       "      <td>46.04</td>\n",
       "      <td>[2880, 2160]</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>./data/videos/individual-rotifer/2024_0201_152...</td>\n",
       "      <td>2024_0201_152431_090.MP4</td>\n",
       "      <td>1.706962e+09</td>\n",
       "      <td>77.79</td>\n",
       "      <td>[2880, 2160]</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>./data/videos/individual-rotifer/2024_0201_152...</td>\n",
       "      <td>2024_0201_152845_091.MP4</td>\n",
       "      <td>1.706962e+09</td>\n",
       "      <td>113.67</td>\n",
       "      <td>[2880, 2160]</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>./data/videos/individual-rotifer/2024_0201_153...</td>\n",
       "      <td>2024_0201_153151_092.MP4</td>\n",
       "      <td>1.706962e+09</td>\n",
       "      <td>212.21</td>\n",
       "      <td>[2880, 2160]</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          file_path  \\\n",
       "0           0  ./data/videos/individual-rotifer/2024_0201_152...   \n",
       "1           1  ./data/videos/individual-rotifer/2024_0201_152...   \n",
       "2           2  ./data/videos/individual-rotifer/2024_0201_152...   \n",
       "3           3  ./data/videos/individual-rotifer/2024_0201_153...   \n",
       "\n",
       "                  file_name      creation  duration    resolution   fps  desc  \n",
       "0  2024_0201_152310_089.MP4  1.706962e+09     46.04  [2880, 2160]  24.0   NaN  \n",
       "1  2024_0201_152431_090.MP4  1.706962e+09     77.79  [2880, 2160]  24.0   NaN  \n",
       "2  2024_0201_152845_091.MP4  1.706962e+09    113.67  [2880, 2160]  24.0   NaN  \n",
       "3  2024_0201_153151_092.MP4  1.706962e+09    212.21  [2880, 2160]  24.0   NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/csvs/metadata_ind-rotifers.csv\")\n",
    "file_name = df.loc[3, \"file_name\"]\n",
    "res = tuple(ast.literal_eval(df.loc[2, \"resolution\"]))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = f\"/Users/mikehemberger/Documents/vscode/rotifer-locomotion/data/videos/individual-rotifer/{file_name}\"\n",
    "os.makedirs(f'/Users/mikehemberger/Documents/vscode/rotifer-locomotion/data/images/{file_name[:-4]}/', exist_ok=True)\n",
    "\n",
    "video = cv2.VideoCapture(fpath)\n",
    "frame_counter = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    if frame_counter % 2 == 0:\n",
    "        # create the new folder at beggining + ADD zfill()\n",
    "        cv2.imwrite(f'/Users/mikehemberger/Documents/vscode/rotifer-locomotion/data/images/{file_name[:-4]}/frame_{frame_counter}.jpg', frame)  \n",
    "    frame_counter += 1\n",
    "video.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make them 224x224 first!\n",
    "original_size = res\n",
    "\n",
    "cdir = f\"/Users/mikehemberger/Documents/vscode/rotifer-locomotion/data/images/{file_name[:-4]}/\"\n",
    "os.makedirs(os.path.join(cdir, \"images-224x224\"), exist_ok=True)\n",
    "\n",
    "ori_imgs = [f for f in os.listdir(cdir) if f.endswith(\".jpg\")]\n",
    "target_imgpaths = [os.path.join(cdir, \"images-224x224\", f.replace(\".jpg\", \"-224x224.jpg\")) for f in ori_imgs]\n",
    "\n",
    "#ori_imgs = [\n",
    "for orig, targ in zip(ori_imgs, target_imgpaths):\n",
    "    oim = Image.open(os.path.join(cdir, orig)).resize((224,224))\n",
    "    oim.save(targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(False)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "img_size = (224,224)\n",
    "norm_tf = transforms.Normalize(mean=[0.485, 0.456, 0.406],  # maybe adjust this for each network?\n",
    "                                        std=[0.229, 0.224, 0.225])\n",
    "\n",
    "tfs = transforms.Compose([\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.ToTensor(),\n",
    "    norm_tf])\n",
    "\n",
    "ds = torchvision.datasets.ImageFolder(root=f\"./data/images/{file_name[:-4]}/\")\n",
    "ds.transform = tfs\n",
    "print(ds)\n",
    "\n",
    "dataloader = DataLoader(ds, batch_size=6, num_workers=4, shuffle=False)\n",
    "\n",
    "vision_model = \"google/vit-base-patch16-224-in21k\"\n",
    "bs_vm, nw_vm = 6, 6\n",
    "\n",
    "# MODEL\n",
    "#vit_feature_extractor = ViTFeatureExtractor.from_pretrained(vision_model)\n",
    "#vit_model = ViTModel.from_pretrained(vision_model, return_dict=True)\n",
    "#vit_model.to(device)\n",
    "\n",
    "\n",
    "model = timm.create_model(\"vit_base_patch16_224_in21k\", pretrained=True, num_classes=0, global_pool=\"avg\").eval()\n",
    "model.to(device)\n",
    "\n",
    "# FEATURES\n",
    "features = list()\n",
    "for nth, (images, labels) in enumerate(dataloader):\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "\n",
    "    features.append(outputs.detach().cpu().numpy())\n",
    "    #print(f\"Processing batch #{nth + 1} / {total_batches}\")\n",
    "\n",
    "    #features.append(outputs.pooler_output.detach().cpu().numpy())\n",
    "\n",
    "# Save feature vectors\n",
    "feature_vectors = np.concatenate(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# T-SNE Setup with equal parameters\n",
    "tsne = TSNE(n_components=2, perplexity=50, early_exaggeration=150, learning_rate=45, random_state=42, init=\"pca\")  # 150, 200, 250\n",
    "\n",
    "embed = tsne.fit_transform(feature_vectors)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(embed[:, 0], embed[:, 1], alpha=.4, edgecolors=\"none\", s=20)\n",
    "plt.axis(\"square\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering\n",
    "time_label = np.arange(0, embed.shape[0], 1)\n",
    "\n",
    "n_clusters = 6\n",
    "kmeans = KMeans(n_clusters=n_clusters, init='k-means++', random_state=42)\n",
    "kmeans.fit(embed)\n",
    "clusters = kmeans.labels_\n",
    "\n",
    "unique_cluster_labels = np.unique(clusters)\n",
    "print(unique_cluster_labels)\n",
    "\n",
    "cmap = plt.get_cmap('bwr')\n",
    "colors = [cmap(i) for i in np.linspace(0, 1, len(unique_cluster_labels))]\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "\n",
    "for nth, cluster in enumerate(unique_cluster_labels):\n",
    "    idx = clusters == cluster\n",
    "    plt.scatter(embed[idx, 0], embed[idx, 1], marker=\"o\", s=5, edgecolors=\"None\", c=colors[nth], alpha=.75)\n",
    "\n",
    "#plt.title(f\"Text Features\")\n",
    "\n",
    "plt.axis(\"equal\")\n",
    "plt.xlabel(\"tSNE dim 1\")\n",
    "plt.ylabel(\"tSNE dim 2\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f\"./{file_name}_tSNE_nclusters_{n_clusters}.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters\n",
    "cluster_indices = dict()\n",
    "\n",
    "for nth, cluster in enumerate(unique_cluster_labels):\n",
    "    idx = np.where(clusters == cluster)[0]\n",
    "    cluster_indices[nth] = idx\n",
    "\n",
    "#cluster_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tfs = transforms.Compose([\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "ds.transform = tfs\n",
    "\n",
    "cclust = cluster_indices[0]\n",
    "\n",
    "for k, v in cluster_indices.items():\n",
    "    l = list()\n",
    "    for nth in v:\n",
    "        l.append(ds.__getitem__(nth)[0])\n",
    "\n",
    "    slist = torch.stack(l)\n",
    "    torchvision.utils.save_image(slist, fp=f\"./{file_name}_individual_cluster_{k}.jpg\", nrow=16)\n",
    "\n",
    "#slist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
